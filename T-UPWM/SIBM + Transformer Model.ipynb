{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from mmnrm.utils import set_random_seed\n",
    "\n",
    "from mmnrm.layers.interaction import SemanticInteractions, ExactInteractions\n",
    "from mmnrm.layers.local_relevance import MultipleNgramConvs, MaskedSoftmax, SimpleMultipleNgramConvs\n",
    "from mmnrm.layers.transformations import *\n",
    "from mmnrm.layers.aggregation import *\n",
    "from mmnrm.modelsv2 import savable_model, mish\n",
    "from mmnrm.dataset import TestCollectionV2, TrainCollectionV2\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "import nltk\n",
    "\n",
    "set_random_seed()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = BertTokenizer.from_pretrained('microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract')\n",
    "\n",
    "def transformer_model(func):\n",
    "    def function_wrapper(**kwargs):\n",
    "        # this setups the entired model tokenizer\n",
    "        \n",
    "        # create tokenizer\n",
    "        if 'checkpoint_name' in kwargs:\n",
    "            tokenizer = BertTokenizer.from_pretrained(kwargs['checkpoint_name'])\n",
    "        else:\n",
    "            raise ValueError('Missing checkpoint_name parameter in the config')\n",
    "       \n",
    "        model = func(**kwargs[\"model\"])\n",
    "        kwargs['func_name'] = func.__name__\n",
    "        model.savable_config = kwargs\n",
    "        model.tokenizer = tokenizer\n",
    "\n",
    "        return model\n",
    "\n",
    "    return function_wrapper\n",
    "\n",
    "\n",
    "def train_test_generator_for_model(model):\n",
    "    \n",
    "    if \"model\" in model.savable_config:\n",
    "        cfg = model.savable_config[\"model\"]\n",
    "    \n",
    "    max_passages = cfg[\"max_passages\"]\n",
    "    max_input_size = cfg[\"max_input_size\"]\n",
    "    tokenizer = model.tokenizer\n",
    "    \n",
    "    def maybe_tokenize_pad(query,document):\n",
    "        if \"tokens\" not in document:\n",
    "            input_sentences = []\n",
    "            sentences =  nltk.sent_tokenize(document[\"text\"])[:max_passages]\n",
    "            \n",
    "            for sentence in sentences:\n",
    "                input_sentences.append([query, sentence])\n",
    "                \n",
    "            document[\"sentences_mask\"] = [True]*len(sentences)+[False]*(max_passages-len(sentences))\n",
    "            \n",
    "            #pad\n",
    "            input_sentences.extend([\"\"]*(max_passages-len(sentences)))\n",
    "\n",
    "            encoded_sentences = tokenizer.batch_encode_plus(\n",
    "                      input_sentences,\n",
    "                      max_length=max_input_size,\n",
    "                      truncation=True,\n",
    "                      add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "                      return_token_type_ids=True,\n",
    "                      padding=\"max_length\",\n",
    "                      return_attention_mask=True,\n",
    "                      return_tensors='np',  # Return tf tensors\n",
    "                )\n",
    "            document[\"tokens\"] = encoded_sentences\n",
    "    \n",
    "    def train_generator(data_generator):\n",
    "        \n",
    "        for query, pos_docs, neg_docs in data_generator:\n",
    "            \n",
    "            pos_input_ids = []\n",
    "            pos_input_masks = []\n",
    "            pos_input_segments = []\n",
    "            pos_input_mask_sentences = []\n",
    "                                                                        \n",
    "            neg_input_ids = []\n",
    "            neg_input_masks = []\n",
    "            neg_input_segments = []\n",
    "            neg_input_mask_sentences = []                                                            \n",
    "                                                                    \n",
    "            for i in range(len(query)):\n",
    "                pos_doc = pos_docs[i]\n",
    "                neg_doc = neg_docs[i]\n",
    "                maybe_tokenize_pad(query[i], pos_doc)\n",
    "                maybe_tokenize_pad(query[i], neg_doc)\n",
    "                \n",
    "                pos_input_ids.append(pos_doc[\"tokens\"][\"input_ids\"])\n",
    "                pos_input_masks.append(pos_doc[\"tokens\"][\"attention_mask\"])\n",
    "                pos_input_segments.append(pos_doc[\"tokens\"][\"token_type_ids\"])\n",
    "                pos_input_mask_sentences.append(pos_doc[\"sentences_mask\"]) \n",
    "                                                                    \n",
    "                neg_input_ids.append(neg_doc[\"tokens\"][\"input_ids\"])\n",
    "                neg_input_masks.append(neg_doc[\"tokens\"][\"attention_mask\"])\n",
    "                neg_input_segments.append(neg_doc[\"tokens\"][\"token_type_ids\"])\n",
    "                neg_input_mask_sentences.append(neg_doc[\"sentences_mask\"]) \n",
    "                                                                        \n",
    "            yield  [np.array(pos_input_ids, dtype=\"int32\"), \n",
    "                    np.array(pos_input_masks, dtype=\"int32\"),\n",
    "                    np.array(pos_input_segments, dtype=\"int32\"),\n",
    "                    np.array(pos_input_mask_sentences, dtype=\"bool\")],\\\n",
    "                   [np.array(neg_input_ids, dtype=\"int32\"), \n",
    "                    np.array(neg_input_masks, dtype=\"int32\"),\n",
    "                    np.array(neg_input_segments, dtype=\"int32\"),\n",
    "                    np.array(neg_input_mask_sentences, dtype=\"bool\")]\n",
    "    \n",
    "    def test_generator(data_generator):\n",
    "        \n",
    "        for ids, queries, docs in data_generator:\n",
    "        \n",
    "            input_query_ids = []\n",
    "\n",
    "            input_ids = []\n",
    "            input_masks = []\n",
    "            input_segments = []\n",
    "\n",
    "            input_mask_sentences = []\n",
    "            docs_info = []\n",
    "\n",
    "            for i in range(len(ids)):\n",
    "                for doc in docs[i]:\n",
    "                    maybe_tokenize_pad(queries[i], doc)\n",
    "                    input_mask_sentences.append(doc[\"sentences_mask\"])\n",
    "                    input_ids.append(doc[\"tokens\"][\"input_ids\"])\n",
    "                    input_masks.append(doc[\"tokens\"][\"attention_mask\"])\n",
    "                    input_segments.append(doc[\"tokens\"][\"token_type_ids\"])\n",
    "                    docs_info.append(doc)\n",
    "                    input_query_ids.append(ids[i])\n",
    "\n",
    "            yield input_query_ids, [np.array(input_ids, dtype=\"int32\"), \n",
    "                                    np.array(input_masks, dtype=\"int32\"),\n",
    "                                    np.array(input_segments, dtype=\"int32\"),\n",
    "                                    np.array(input_mask_sentences, dtype=\"bool\")], docs_info\n",
    "    \n",
    "    return train_generator, test_generator\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AprioriLayerWmask(TrainableLayer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(AprioriLayerWmask, self).__init__()\n",
    "        \n",
    "        self.qtw_layer = QueryTermWeighting()\n",
    "        \n",
    "    def call(self, x):\n",
    "        \n",
    "        query_embeddings, query_mask, query_matches = x\n",
    "        \n",
    "        query_emb = query_embeddings * tf.expand_dims(query_mask, axis=-1)\n",
    "\n",
    "        query_weights = self.qtw_layer(query_emb, mask=query_mask)\n",
    "\n",
    "        return tf.reduce_sum(query_weights * query_matches, axis=-1, keepdims=True)\n",
    "\n",
    "@transformer_model\n",
    "def sibmtransfomer(max_passages = 20,\n",
    "                   max_input_size = 128,\n",
    "                   match_threshold = 0.8,\n",
    "                   apriori_exact_match = False,\n",
    "                   bert_train = False,\n",
    "                   hidden_size = 768,\n",
    "                   activation = \"mish\",\n",
    "                   top_k_list = [3,5,10,15],): \n",
    "    \n",
    "    if activation==\"mish\":\n",
    "        activation = mish\n",
    "    \n",
    "    input_ids = tf.keras.layers.Input((max_passages, max_input_size,), dtype=\"int32\") #\n",
    "    input_masks = tf.keras.layers.Input((max_passages, max_input_size, ), dtype=\"int32\") #\n",
    "    input_segments = tf.keras.layers.Input((max_passages, max_input_size, ), dtype=\"int32\") # \n",
    "    input_mask_passages = tf.keras.layers.Input((max_passages,), dtype=\"bool\") # (None, P)\n",
    "    \n",
    "    bert_model = TFBertModel.from_pretrained('microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract', \n",
    "                                             output_attentions = False,\n",
    "                                             output_hidden_states = False,\n",
    "                                             return_dict=True,\n",
    "                                             from_pt=True)\n",
    "    bert_model.trainable = bert_train\n",
    "    \n",
    "    apriori_layer = AprioriLayerWmask()\n",
    "    \n",
    "    def skip_padding_data(input_ids, input_masks, input_segments, input_mask_passages):\n",
    "        mask_passages = tf.reshape(input_mask_passages, shape=(-1,)) #None, 1\n",
    "        mask_passages_indices = tf.cast(tf.where(mask_passages), tf.int32)\n",
    "    \n",
    "        input_ids = tf.gather_nd(tf.reshape(input_ids, shape=(-1, 128)),mask_passages_indices)\n",
    "        input_masks = tf.gather_nd(tf.reshape(input_masks, shape=(-1, 128)),mask_passages_indices)\n",
    "        input_segments = tf.gather_nd(tf.reshape(input_segments, shape=(-1, 128)),mask_passages_indices)\n",
    "        \n",
    "        return input_ids, input_masks, input_segments, mask_passages, mask_passages_indices\n",
    "    \n",
    "    def bert_contextualized_embeddings(input_ids, input_masks, input_segments):\n",
    "        \n",
    "        output = bert_model([input_ids, input_masks, input_segments])\n",
    "        print(output)\n",
    "        print(len(output))\n",
    "        return output.pooler_output, output.last_hidden_state[:,1:,:]\n",
    "    \n",
    "    def embedding_matches_layer(embeddings, input_ids, input_masks, input_segments):\n",
    "        \n",
    "        #embeddings = x[0][:,1:,:] \n",
    "        #input_ids = x[1][:,1:]\n",
    "        #input_masks = x[2][:,1:]\n",
    "        #input_segments = x[3][:,1:]\n",
    "        \n",
    "        input_ids = input_ids[:,1:]\n",
    "        input_masks = input_masks[:,1:]\n",
    "        input_segments = input_segments[:,1:]\n",
    "        \n",
    "        # query mask, that will ignore the sep tokens\n",
    "        #print(input_masks)\n",
    "        #print(input_segments)\n",
    "        mask_q = ((input_masks+input_segments)==1)\n",
    "        mask_sep_tokens = input_ids == 3\n",
    "        mask_q = tf.cast(tf.math.logical_xor(mask_sep_tokens,  (mask_q | mask_sep_tokens)), tf.float32)\n",
    "        \n",
    "        # sentence mask\n",
    "        mask_s = tf.cast((input_segments==1), tf.float32)\n",
    "        \n",
    "        mask_interaction = tf.einsum(\"bq,bs->bqs\", mask_q, mask_s)\n",
    "        \n",
    "        if apriori_exact_match:\n",
    "            \n",
    "            interaction_matrix = tf.cast(tf.einsum(\"bq,bs->bqs\", input_ids, input_ids)==tf.expand_dims(tf.square(input_ids),axis=-1), tf.float32) * mask_interaction  \n",
    "        else:\n",
    "            ## using the embedding to perform the exact matching extraction\n",
    "            embeddings = embeddings / tf.norm(embeddings, axis=-1, keepdims=True)\n",
    "\n",
    "            interaction_matrix = tf.einsum(\"bqe,bse->bqs\", embeddings, embeddings) * mask_interaction\n",
    "            \n",
    "        query_matches = tf.cast(tf.reduce_sum(tf.cast(interaction_matrix >= match_threshold, tf.int8), axis=-1)>0,tf.float32)\n",
    "        \n",
    "        return query_matches, mask_q\n",
    "    \n",
    "    l1_sentences_score = tf.keras.layers.Dense(1024, activation=activation)\n",
    "    l2_sentences_score = tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    \n",
    "    def sentences_scores_layer(cls_embedding):\n",
    "        \n",
    "        x = l1_sentences_score(cls_embedding)\n",
    "        x = l2_sentences_score(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def document_features_layer(sentences_score, apriori_score, mask_passages, mask_passages_indices):\n",
    "\n",
    "        x = apriori_score * sentences_score\n",
    "\n",
    "        x = tf.scatter_nd(mask_passages_indices, tf.squeeze(x), tf.shape(mask_passages))\n",
    "        \n",
    "        x = tf.reshape(x, shape=(-1,max_passages,))\n",
    "        \n",
    "        top_k, indices = tf.math.top_k(x, k=top_k_list[-1], sorted=True)\n",
    "        \n",
    "        sentence_features = [tf.expand_dims(tf.math.reduce_max(x, axis=-1),axis=-1), \n",
    "                             tf.expand_dims(tf.math.reduce_sum(x, axis=-1),axis=-1), \n",
    "                             tf.expand_dims(tf.math.reduce_mean(x, axis=-1),axis=-1),\n",
    "                            ]\n",
    "        \n",
    "        sentence_features += [ tf.expand_dims(tf.math.reduce_mean(top_k[:,:k], axis=-1),axis=-1) for k in top_k_list]\n",
    "        \n",
    "        return tf.concat(sentence_features, axis=-1)\n",
    "        \n",
    "    \n",
    "    l1_score = tf.keras.layers.Dense(max_passages, activation=activation)\n",
    "    l2_score = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    def document_score(x):\n",
    "        x = l1_score(x)\n",
    "        x = l2_score(x)\n",
    "        return x\n",
    "    \n",
    "    ## forward pass\n",
    "    data_ids, data_masks, data_segments, mask_passages, mask_passages_indices = skip_padding_data(input_ids, input_masks, input_segments, input_mask_passages)\n",
    "    \n",
    "    cls_embedding, embeddings = bert_contextualized_embeddings(data_ids, data_masks, data_segments)\n",
    "    \n",
    "    query_matches, query_mask = embedding_matches_layer(embeddings, data_ids, data_masks, data_segments)\n",
    "    \n",
    "    sentence_scores = sentences_scores_layer(cls_embedding)\n",
    "    \n",
    "    apriori_scores = apriori_layer([embeddings, query_mask, query_matches])\n",
    "    \n",
    "    document_features = document_features_layer(sentence_scores, apriori_scores, mask_passages, mask_passages_indices)\n",
    "    \n",
    "    output_list = [document_score(document_features)]\n",
    "    \n",
    "    return tf.keras.models.Model(inputs=[input_ids, input_masks, input_segments, input_mask_passages], outputs=output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFBaseModelOutputWithPooling(last_hidden_state=<tf.Tensor 'tf_bert_model_2/Identity:0' shape=(None, 128, 768) dtype=float32>, pooler_output=<tf.Tensor 'tf_bert_model_2/Identity_1:0' shape=(None, 768) dtype=float32>, hidden_states=None, attentions=None)\n",
      "2\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_5 (TensorFl [(None,)]            0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Where_1 (TensorFlow [(None, 1)]          0           tf_op_layer_Reshape_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 20, 128)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            [(None, 20, 128)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Cast_5 (TensorFlowO [(None, 1)]          0           tf_op_layer_Where_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 20, 128)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_7 (TensorFl [(None, 128)]        0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_8 (TensorFl [(None, 128)]        0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_6 (TensorFl [(None, 128)]        0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherNd_4 (TensorF [(None, 128)]        0           tf_op_layer_Reshape_7[0][0]      \n",
      "                                                                 tf_op_layer_Cast_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherNd_5 (TensorF [(None, 128)]        0           tf_op_layer_Reshape_8[0][0]      \n",
      "                                                                 tf_op_layer_Cast_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GatherNd_3 (TensorF [(None, 128)]        0           tf_op_layer_Reshape_6[0][0]      \n",
      "                                                                 tf_op_layer_Cast_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_10 (T [(None, 127)]        0           tf_op_layer_GatherNd_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_11 (T [(None, 127)]        0           tf_op_layer_GatherNd_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_9 (Te [(None, 127)]        0           tf_op_layer_GatherNd_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_1 (TensorFlow [(None, 127)]        0           tf_op_layer_strided_slice_10[0][0\n",
      "                                                                 tf_op_layer_strided_slice_11[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model_2 (TFBertModel)   TFBaseModelOutputWit 109482240   tf_op_layer_GatherNd_3[0][0]     \n",
      "                                                                 tf_op_layer_GatherNd_4[0][0]     \n",
      "                                                                 tf_op_layer_GatherNd_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Equal_4 (TensorFlow [(None, 127)]        0           tf_op_layer_strided_slice_9[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Equal_3 (TensorFlow [(None, 127)]        0           tf_op_layer_AddV2_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_8 (Te [(None, 127, 768)]   0           tf_bert_model_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_LogicalOr_2 (Tensor [(None, 127)]        0           tf_op_layer_Equal_3[0][0]        \n",
      "                                                                 tf_op_layer_Equal_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_LogicalAnd_1 (Tenso [(None, 127)]        0           tf_op_layer_Equal_4[0][0]        \n",
      "                                                                 tf_op_layer_LogicalOr_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_3 (TensorFlowOp [(None, 127, 768)]   0           tf_op_layer_strided_slice_8[0][0]\n",
      "                                                                 tf_op_layer_strided_slice_8[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_LogicalOr_3 (Tensor [(None, 127)]        0           tf_op_layer_Equal_4[0][0]        \n",
      "                                                                 tf_op_layer_LogicalOr_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_LogicalNot_1 (Tenso [(None, 127)]        0           tf_op_layer_LogicalAnd_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_3 (TensorFlowOp [(None, 127, 1)]     0           tf_op_layer_Mul_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_LogicalXor_1 (Tenso [(None, 127)]        0           tf_op_layer_LogicalOr_3[0][0]    \n",
      "                                                                 tf_op_layer_LogicalNot_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sqrt_1 (TensorFlowO [(None, 127, 1)]     0           tf_op_layer_Sum_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Equal_5 (TensorFlow [(None, 127)]        0           tf_op_layer_strided_slice_11[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Cast_6 (TensorFlowO [(None, 127)]        0           tf_op_layer_LogicalXor_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_RealDiv_1 (TensorFl [(None, 127, 768)]   0           tf_op_layer_strided_slice_8[0][0]\n",
      "                                                                 tf_op_layer_Sqrt_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Cast_7 (TensorFlowO [(None, 127)]        0           tf_op_layer_Equal_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Einsum_3 (TensorFlo [(None, 127, 127)]   0           tf_op_layer_RealDiv_1[0][0]      \n",
      "                                                                 tf_op_layer_RealDiv_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Einsum_2 (TensorFlo [(None, 127, 127)]   0           tf_op_layer_Cast_6[0][0]         \n",
      "                                                                 tf_op_layer_Cast_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_4 (TensorFlowOp [(None, 127, 127)]   0           tf_op_layer_Einsum_3[0][0]       \n",
      "                                                                 tf_op_layer_Einsum_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_GreaterEqual_1 (Ten [(None, 127, 127)]   0           tf_op_layer_Mul_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Cast_8 (TensorFlowO [(None, 127, 127)]   0           tf_op_layer_GreaterEqual_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_4 (TensorFlowOp [(None, 127)]        0           tf_op_layer_Cast_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Greater_1 (TensorFl [(None, 127)]        0           tf_op_layer_Sum_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Cast_9 (TensorFlowO [(None, 127)]        0           tf_op_layer_Greater_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1024)         787456      tf_bert_model_2[0][1]            \n",
      "__________________________________________________________________________________________________\n",
      "apriori_layer_wmask_1 (AprioriL (None, 1)            768         tf_op_layer_strided_slice_8[0][0]\n",
      "                                                                 tf_op_layer_Cast_6[0][0]         \n",
      "                                                                 tf_op_layer_Cast_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            1025        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_5 (TensorFlowOp [(None, 1)]          0           apriori_layer_wmask_1[0][0]      \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze_1 (TensorFl [None]               0           tf_op_layer_Mul_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_1 (TensorFlow [(1,)]               0           tf_op_layer_Reshape_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ScatterNd_1 (Tensor [(None,)]            0           tf_op_layer_Cast_5[0][0]         \n",
      "                                                                 tf_op_layer_Squeeze_1[0][0]      \n",
      "                                                                 tf_op_layer_Shape_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_9 (TensorFl [(None, 20)]         0           tf_op_layer_ScatterNd_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_TopKV2_1 (TensorFlo [(None, 15), (None,  0           tf_op_layer_Reshape_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_12 (T [(None, 3)]          0           tf_op_layer_TopKV2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_13 (T [(None, 5)]          0           tf_op_layer_TopKV2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_14 (T [(None, 10)]         0           tf_op_layer_TopKV2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_15 (T [(None, 15)]         0           tf_op_layer_TopKV2_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Max_1 (TensorFlowOp [(None,)]            0           tf_op_layer_Reshape_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_5 (TensorFlowOp [(None,)]            0           tf_op_layer_Reshape_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_5 (TensorFlowO [(None,)]            0           tf_op_layer_Reshape_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_6 (TensorFlowO [(None,)]            0           tf_op_layer_strided_slice_12[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_7 (TensorFlowO [(None,)]            0           tf_op_layer_strided_slice_13[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_8 (TensorFlowO [(None,)]            0           tf_op_layer_strided_slice_14[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_9 (TensorFlowO [(None,)]            0           tf_op_layer_strided_slice_15[0][0\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_7 (Tenso [(None, 1)]          0           tf_op_layer_Max_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_8 (Tenso [(None, 1)]          0           tf_op_layer_Sum_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_9 (Tenso [(None, 1)]          0           tf_op_layer_Mean_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_10 (Tens [(None, 1)]          0           tf_op_layer_Mean_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_11 (Tens [(None, 1)]          0           tf_op_layer_Mean_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_12 (Tens [(None, 1)]          0           tf_op_layer_Mean_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_13 (Tens [(None, 1)]          0           tf_op_layer_Mean_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_1 (TensorFlo [(None, 7)]          0           tf_op_layer_ExpandDims_7[0][0]   \n",
      "                                                                 tf_op_layer_ExpandDims_8[0][0]   \n",
      "                                                                 tf_op_layer_ExpandDims_9[0][0]   \n",
      "                                                                 tf_op_layer_ExpandDims_10[0][0]  \n",
      "                                                                 tf_op_layer_ExpandDims_11[0][0]  \n",
      "                                                                 tf_op_layer_ExpandDims_12[0][0]  \n",
      "                                                                 tf_op_layer_ExpandDims_13[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 20)           160         tf_op_layer_concat_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            21          dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 110,271,670\n",
      "Trainable params: 789,430\n",
      "Non-trainable params: 109,482,240\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cfg = {\n",
    "    \"checkpoint_name\":'microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract',\n",
    "    \"model\":{\n",
    "        \"max_passages\" : 20,\n",
    "        \"max_input_size\" : 128,\n",
    "        \"match_threshold\" : 0.9,\n",
    "    }\n",
    "}\n",
    "\n",
    "rank_model = sibmtransfomer(**cfg)\n",
    "\n",
    "rank_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen, test_gen = train_test_generator_for_model(rank_model)\n",
    "\n",
    "train_collection = TrainCollectionV2\\\n",
    "                                .load(\"training_batch_01_250\")\\\n",
    "                                .batch_size(32)\\\n",
    "                                .set_transform_inputs_fn(train_gen)\n",
    "\n",
    "inference_data = TestCollectionV2.load(\"validation_data_batch_01_250\")\\\n",
    "                           .batch_size(32)\\\n",
    "                           .set_transform_inputs_fn(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for pos, neg in train_collection.generator():\n",
    "    \n",
    "pos, neg = next(train_collection.generator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_model(next(inference_data.generator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "train_collection = TrainCollectionV2\\\n",
    "                                .load(\"training_batch_01_250\")\\\n",
    "                                .batch_size(32)\\\n",
    "\n",
    "docs_len = []\n",
    "sentences_len = []\n",
    "n_sentences = []\n",
    "\n",
    "gen = train_collection.generator()\n",
    "for j in range(850*5):\n",
    "    \n",
    "    if j% 1000 == 0:\n",
    "        print(j)\n",
    "            \n",
    "    query, pos_docs, neg = next(gen)\n",
    "\n",
    "    for batch_index in range(len(pos_docs)):\n",
    "\n",
    "        docs_len.append(len(pos_docs[batch_index][\"text\"]))\n",
    "        split = nltk.sent_tokenize(pos_docs[batch_index][\"text\"])\n",
    "        n_sentences.append(len(split))\n",
    "        sentences_len.extend([ len(x) for x in split])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.9900e+02, 1.6950e+03, 4.0610e+03, 8.1840e+03, 1.2679e+04,\n",
       "        1.9130e+04, 2.1487e+04, 2.0994e+04, 1.9379e+04, 1.3286e+04,\n",
       "        6.0670e+03, 3.0390e+03, 2.1940e+03, 1.2570e+03, 6.7500e+02,\n",
       "        2.3800e+02, 1.6900e+02, 2.7300e+02, 1.9500e+02, 7.9000e+01,\n",
       "        5.7000e+01, 1.2200e+02, 5.7000e+01, 4.1000e+01, 3.5000e+01,\n",
       "        1.4000e+01, 7.0000e+00, 2.0000e+00, 1.7000e+01, 2.2000e+01,\n",
       "        2.0000e+00, 9.0000e+00, 0.0000e+00, 0.0000e+00, 5.0000e+00,\n",
       "        1.3000e+01, 5.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0000e+00]),\n",
       " array([ 140.  ,  334.72,  529.44,  724.16,  918.88, 1113.6 , 1308.32,\n",
       "        1503.04, 1697.76, 1892.48, 2087.2 , 2281.92, 2476.64, 2671.36,\n",
       "        2866.08, 3060.8 , 3255.52, 3450.24, 3644.96, 3839.68, 4034.4 ,\n",
       "        4229.12, 4423.84, 4618.56, 4813.28, 5008.  , 5202.72, 5397.44,\n",
       "        5592.16, 5786.88, 5981.6 , 6176.32, 6371.04, 6565.76, 6760.48,\n",
       "        6955.2 , 7149.92, 7344.64, 7539.36, 7734.08, 7928.8 , 8123.52,\n",
       "        8318.24, 8512.96, 8707.68, 8902.4 , 9097.12, 9291.84, 9486.56,\n",
       "        9681.28, 9876.  ]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(docs_len, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.6400e+02, 9.6300e+02, 2.6120e+03, 4.8420e+03, 2.1825e+04,\n",
       "        1.6642e+04, 1.6725e+04, 1.7275e+04, 1.5085e+04, 2.0728e+04,\n",
       "        5.5980e+03, 4.3090e+03, 2.9250e+03, 3.1340e+03, 8.5900e+02,\n",
       "        6.8000e+02, 3.3900e+02, 2.8700e+02, 2.7500e+02, 6.7000e+01,\n",
       "        1.1400e+02, 1.1800e+02, 4.5000e+01, 1.7000e+01, 1.6000e+01,\n",
       "        2.2000e+01, 2.3000e+01, 3.7000e+01, 8.0000e+00, 8.0000e+00,\n",
       "        8.0000e+00, 8.0000e+00, 2.0000e+00, 1.7000e+01, 1.3000e+01,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0000e+00, 2.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 5.0000e+00]),\n",
       " array([ 1.  ,  2.22,  3.44,  4.66,  5.88,  7.1 ,  8.32,  9.54, 10.76,\n",
       "        11.98, 13.2 , 14.42, 15.64, 16.86, 18.08, 19.3 , 20.52, 21.74,\n",
       "        22.96, 24.18, 25.4 , 26.62, 27.84, 29.06, 30.28, 31.5 , 32.72,\n",
       "        33.94, 35.16, 36.38, 37.6 , 38.82, 40.04, 41.26, 42.48, 43.7 ,\n",
       "        44.92, 46.14, 47.36, 48.58, 49.8 , 51.02, 52.24, 53.46, 54.68,\n",
       "        55.9 , 57.12, 58.34, 59.56, 60.78, 62.  ]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(n_sentences, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5.29560e+04, 3.36493e+05, 4.45121e+05, 3.06245e+05, 1.41374e+05,\n",
       "        5.69360e+04, 2.04260e+04, 7.09000e+03, 3.08100e+03, 1.21700e+03,\n",
       "        6.50000e+02, 3.60000e+02, 1.30000e+02, 1.41000e+02, 6.60000e+01,\n",
       "        5.20000e+01, 3.30000e+01, 2.20000e+01, 1.80000e+01, 2.30000e+01,\n",
       "        1.50000e+01, 0.00000e+00, 0.00000e+00, 1.30000e+01, 2.00000e+00,\n",
       "        0.00000e+00, 3.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 7.00000e+00]),\n",
       " array([1.00000e+00, 5.35200e+01, 1.06040e+02, 1.58560e+02, 2.11080e+02,\n",
       "        2.63600e+02, 3.16120e+02, 3.68640e+02, 4.21160e+02, 4.73680e+02,\n",
       "        5.26200e+02, 5.78720e+02, 6.31240e+02, 6.83760e+02, 7.36280e+02,\n",
       "        7.88800e+02, 8.41320e+02, 8.93840e+02, 9.46360e+02, 9.98880e+02,\n",
       "        1.05140e+03, 1.10392e+03, 1.15644e+03, 1.20896e+03, 1.26148e+03,\n",
       "        1.31400e+03, 1.36652e+03, 1.41904e+03, 1.47156e+03, 1.52408e+03,\n",
       "        1.57660e+03, 1.62912e+03, 1.68164e+03, 1.73416e+03, 1.78668e+03,\n",
       "        1.83920e+03, 1.89172e+03, 1.94424e+03, 1.99676e+03, 2.04928e+03,\n",
       "        2.10180e+03, 2.15432e+03, 2.20684e+03, 2.25936e+03, 2.31188e+03,\n",
       "        2.36440e+03, 2.41692e+03, 2.46944e+03, 2.52196e+03, 2.57448e+03,\n",
       "        2.62700e+03]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sentences_len, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(docs_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 20, 128, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 20, 128, 768), dtype=tf.int32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (32, 20, 128).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 20, 128, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 20, 128, 768), dtype=tf.int32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (32, 20, 128).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 20, 128, 768) for input KerasTensor(type_spec=TensorSpec(shape=(None, 20, 128, 768), dtype=tf.int32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (32, 20, 128).\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 1), dtype=float32, numpy=\n",
       "array([[0.2021012 ],\n",
       "       [0.16349386],\n",
       "       [0.15401535],\n",
       "       [0.08774568],\n",
       "       [0.13155523],\n",
       "       [0.18557489],\n",
       "       [0.12081145],\n",
       "       [0.28720528],\n",
       "       [0.13876571],\n",
       "       [0.21661234],\n",
       "       [0.22450313],\n",
       "       [0.2667594 ],\n",
       "       [0.42713922],\n",
       "       [0.17484169],\n",
       "       [0.3498851 ],\n",
       "       [0.18980098],\n",
       "       [0.20608734],\n",
       "       [0.19867793],\n",
       "       [0.12750882],\n",
       "       [0.05447982],\n",
       "       [0.23414981],\n",
       "       [0.13473289],\n",
       "       [0.18844184],\n",
       "       [0.09229364],\n",
       "       [0.278794  ],\n",
       "       [0.2618987 ],\n",
       "       [0.13536623],\n",
       "       [0.28666207],\n",
       "       [0.21383315],\n",
       "       [0.1153321 ],\n",
       "       [0.28572255],\n",
       "       [0.1950675 ]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def untraced_static_model(kwargs):\n",
    "    return rank_model(kwargs)\n",
    "\n",
    "traced_model = untraced_static_model.get_concrete_function((next(train_collection.generator())[0]))\n",
    "\n",
    "traced_model(pos) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3033a08536d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/BioASQ-9b-Transformer/py-bioasq/lib/python3.6/site-packages/mmnrm/training.py\u001b[0m in \u001b[0;36mgenerator\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;31m# finally yield the input to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen_X\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-f909d7a9c487>\u001b[0m in \u001b[0;36mtrain_generator\u001b[0;34m(data_generator)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mneg_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneg_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mmaybe_tokenize_pad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_doc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0mmaybe_tokenize_pad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_doc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0mpos_input_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_doc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-f909d7a9c487>\u001b[0m in \u001b[0;36mmaybe_tokenize_pad\u001b[0;34m(query, document)\u001b[0m\n\u001b[1;32m     51\u001b[0m                       \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max_length\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                       \u001b[0mreturn_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                       \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'np'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Return tf tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m                 )\n\u001b[1;32m     55\u001b[0m             \u001b[0mdocument\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded_sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/BioASQ-9b-Transformer/py-bioasq/lib/python3.6/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mbatch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2530\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2531\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2532\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2533\u001b[0m         )\n\u001b[1;32m   2534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/BioASQ-9b-Transformer/py-bioasq/lib/python3.6/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0mfirst_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0msecond_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpair_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/BioASQ-9b-Transformer/py-bioasq/lib/python3.6/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mget_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m                 \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/BioASQ-9b-Transformer/py-bioasq/lib/python3.6/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0mno_split_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_no_split_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0mtokenized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_on_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_split_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/BioASQ-9b-Transformer/py-bioasq/lib/python3.6/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36msplit_on_tokens\u001b[0;34m(tok_list, text)\u001b[0m\n\u001b[1;32m    334\u001b[0m                     (\n\u001b[1;32m    335\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_no_split_tokens\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m                         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m                     )\n\u001b[1;32m    338\u001b[0m                 )\n",
      "\u001b[0;32m~/BioASQ-9b-Transformer/py-bioasq/lib/python3.6/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    334\u001b[0m                     (\n\u001b[1;32m    335\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_no_split_tokens\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m                         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m                     )\n\u001b[1;32m    338\u001b[0m                 )\n",
      "\u001b[0;32m~/BioASQ-9b-Transformer/py-bioasq/lib/python3.6/site-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36m_tokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0msplit_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_basic_tokenize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnever_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_special_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0;31m# If the token is part of the never_split set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/BioASQ-9b-Transformer/py-bioasq/lib/python3.6/site-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, never_split)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# union() returns a new set by concatenating the two sets.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mnever_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnever_split\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnever_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnever_split\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnever_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;31m# This was added on November 1st, 2018 for the multilingual and Chinese\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/BioASQ-9b-Transformer/py-bioasq/lib/python3.6/site-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36m_clean_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m                 \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## run to the data training\n",
    "\n",
    "count = 0\n",
    "for pos, neg in train_collection.generator():\n",
    "    count += 1\n",
    "    if count%20:\n",
    "        print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## inputs to test\n",
    "max_passages = 20\n",
    "\n",
    "def input_generator(data_generator):\n",
    "    \n",
    "    \n",
    "    for ids, queries, docs in data_generator:\n",
    "        \n",
    "        input_query_ids = []\n",
    "\n",
    "        input_ids = []\n",
    "        input_masks = []\n",
    "        input_segments = []\n",
    "\n",
    "        input_text = []\n",
    "        input_mask_sentences = []\n",
    "        docs_info = []\n",
    "        \n",
    "        for i in range(len(ids)):\n",
    "            for doc in docs[i]:\n",
    "                input_sentences = []\n",
    "                sentences =  nltk.sent_tokenize(doc[\"text\"])[:20]\n",
    "                for sentence in sentences:\n",
    "                    input_sentences.append([queries[i],sentence])\n",
    "                input_mask_sentences.append([True]*len(sentences)+[False]*(max_passages-len(sentences)))\n",
    "                #pad\n",
    "                input_sentences.extend([\"\"]*(20-len(sentences)))\n",
    "                \n",
    "                encoded_sentences = tokenizer.batch_encode_plus(\n",
    "                          input_sentences,\n",
    "                          max_length=128,\n",
    "                          truncation=True,\n",
    "                          add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "                          return_token_type_ids=True,\n",
    "                          padding=\"max_length\",\n",
    "                          return_attention_mask=True,\n",
    "                          return_tensors='np',  # Return tf tensors\n",
    "                    )\n",
    "                input_ids.append(encoded_sentences[\"input_ids\"])\n",
    "                input_masks.append(encoded_sentences[\"attention_mask\"])\n",
    "                input_segments.append(encoded_sentences[\"token_type_ids\"])\n",
    "                docs_info.append(doc)\n",
    "                input_query_ids.append(ids[i])\n",
    "        \n",
    "        yield input_query_ids, [np.array(input_ids, dtype=\"int32\"), \n",
    "                                np.array(input_masks, dtype=\"int32\"),\n",
    "                                np.array(input_segments, dtype=\"int32\"),\n",
    "                                np.array(input_mask_sentences, dtype=\"bool\")], docs_info\n",
    "\n",
    "inference_data = TestCollectionV2.load(\"validation_data_batch_01_250\")\\\n",
    "                           .batch_size(10)\\\n",
    "                           .set_transform_inputs_fn(input_generator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(inference_data.generator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       "array([[-0.24755947],\n",
       "       [-0.11821245],\n",
       "       [-0.52642405],\n",
       "       [-0.40074426],\n",
       "       [-0.23962358],\n",
       "       [-0.2918184 ],\n",
       "       [-0.24602206],\n",
       "       [-0.21049237],\n",
       "       [-0.24049833],\n",
       "       [-0.28115588]], dtype=float32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_model(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[   2 1810 7760 ...    0    0    0]\n",
      "  [   2 1810 7760 ...    0    0    0]\n",
      "  [   2 1810 7760 ...    0    0    0]\n",
      "  ...\n",
      "  [   2    3    0 ...    0    0    0]\n",
      "  [   2    3    0 ...    0    0    0]\n",
      "  [   2    3    0 ...    0    0    0]]\n",
      "\n",
      " [[   2 1810 7760 ...    0    0    0]\n",
      "  [   2 1810 7760 ...    0    0    0]\n",
      "  [   2 1810 7760 ...    0    0    0]\n",
      "  ...\n",
      "  [   2    3    0 ...    0    0    0]\n",
      "  [   2    3    0 ...    0    0    0]\n",
      "  [   2    3    0 ...    0    0    0]]\n",
      "\n",
      " [[   2 1810 7760 ...    0    0    0]\n",
      "  [   2 1810 7760 ...    0    0    0]\n",
      "  [   2 1810 7760 ...    0    0    0]\n",
      "  ...\n",
      "  [   2    3    0 ...    0    0    0]\n",
      "  [   2    3    0 ...    0    0    0]\n",
      "  [   2    3    0 ...    0    0    0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[   2 1810 7760 ...    0    0    0]\n",
      "  [   2 1810 7760 ...    0    0    0]\n",
      "  [   2 1810 7760 ...    0    0    0]\n",
      "  ...\n",
      "  [   2    3    0 ...    0    0    0]\n",
      "  [   2    3    0 ...    0    0    0]\n",
      "  [   2    3    0 ...    0    0    0]]\n",
      "\n",
      " [[   2 1810 7760 ...    0    0    0]\n",
      "  [   2 1810 7760 ...    0    0    0]\n",
      "  [   2 1810 7760 ...    0    0    0]\n",
      "  ...\n",
      "  [   2    3    0 ...    0    0    0]\n",
      "  [   2    3    0 ...    0    0    0]\n",
      "  [   2    3    0 ...    0    0    0]]\n",
      "\n",
      " [[   2 1810 7760 ...    0    0    0]\n",
      "  [   2 1810 7760 ...    0    0    0]\n",
      "  [   2 1810 7760 ...    0    0    0]\n",
      "  ...\n",
      "  [   2    3    0 ...    0    0    0]\n",
      "  [   2    3    0 ...    0    0    0]\n",
      "  [   2    3    0 ...    0    0    0]]]\n",
      "(113, 128) (113, 128) (113, 128)\n"
     ]
    }
   ],
   "source": [
    "a = next(gen)\n",
    "\n",
    "\n",
    "\n",
    "Y0,Y1,Y2 = a[1][0],a[1][1],a[1][2]\n",
    "\n",
    "print(Y0)\n",
    "\n",
    "mask_passages = tf.reshape(a[2], shape=(-1,)) #None, 1\n",
    "mask_passages_indices = tf.cast(tf.where(mask_passages), tf.int32)\n",
    "\n",
    "Y0 = tf.gather_nd(tf.reshape(Y0, shape=(-1, 128)),mask_passages_indices)\n",
    "Y1 = tf.gather_nd(tf.reshape(Y1, shape=(-1, 128)),mask_passages_indices)\n",
    "Y2 = tf.gather_nd(tf.reshape(Y2, shape=(-1, 128)),mask_passages_indices)\n",
    "\n",
    "print(Y0.shape,Y1.shape,Y2.shape)\n",
    "\n",
    "output = model([Y0,Y1,Y2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[   2, 1810, 7760, ...,    0,    0,    0],\n",
       "         [   2, 1810, 7760, ...,    0,    0,    0],\n",
       "         [   2, 1810, 7760, ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [   2,    3,    0, ...,    0,    0,    0],\n",
       "         [   2,    3,    0, ...,    0,    0,    0],\n",
       "         [   2,    3,    0, ...,    0,    0,    0]],\n",
       "\n",
       "        [[   2, 1810, 7760, ...,    0,    0,    0],\n",
       "         [   2, 1810, 7760, ...,    0,    0,    0],\n",
       "         [   2, 1810, 7760, ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [   2,    3,    0, ...,    0,    0,    0],\n",
       "         [   2,    3,    0, ...,    0,    0,    0],\n",
       "         [   2,    3,    0, ...,    0,    0,    0]],\n",
       "\n",
       "        [[   2, 1810, 7760, ...,    0,    0,    0],\n",
       "         [   2, 1810, 7760, ...,    0,    0,    0],\n",
       "         [   2, 1810, 7760, ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [   2,    3,    0, ...,    0,    0,    0],\n",
       "         [   2,    3,    0, ...,    0,    0,    0],\n",
       "         [   2,    3,    0, ...,    0,    0,    0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[   2, 1810, 7760, ...,    0,    0,    0],\n",
       "         [   2, 1810, 7760, ...,    0,    0,    0],\n",
       "         [   2, 1810, 7760, ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [   2,    3,    0, ...,    0,    0,    0],\n",
       "         [   2,    3,    0, ...,    0,    0,    0],\n",
       "         [   2,    3,    0, ...,    0,    0,    0]],\n",
       "\n",
       "        [[   2, 1810, 7760, ...,    0,    0,    0],\n",
       "         [   2, 1810, 7760, ...,    0,    0,    0],\n",
       "         [   2, 1810, 7760, ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [   2,    3,    0, ...,    0,    0,    0],\n",
       "         [   2,    3,    0, ...,    0,    0,    0],\n",
       "         [   2,    3,    0, ...,    0,    0,    0]],\n",
       "\n",
       "        [[   2, 1810, 7760, ...,    0,    0,    0],\n",
       "         [   2, 1810, 7760, ...,    0,    0,    0],\n",
       "         [   2, 1810, 7760, ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [   2,    3,    0, ...,    0,    0,    0],\n",
       "         [   2,    3,    0, ...,    0,    0,    0],\n",
       "         [   2,    3,    0, ...,    0,    0,    0]]],\n",
       "\n",
       "\n",
       "       [[[   1,    1,    1, ...,    0,    0,    0],\n",
       "         [   1,    1,    1, ...,    0,    0,    0],\n",
       "         [   1,    1,    1, ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [   1,    1,    0, ...,    0,    0,    0],\n",
       "         [   1,    1,    0, ...,    0,    0,    0],\n",
       "         [   1,    1,    0, ...,    0,    0,    0]],\n",
       "\n",
       "        [[   1,    1,    1, ...,    0,    0,    0],\n",
       "         [   1,    1,    1, ...,    0,    0,    0],\n",
       "         [   1,    1,    1, ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [   1,    1,    0, ...,    0,    0,    0],\n",
       "         [   1,    1,    0, ...,    0,    0,    0],\n",
       "         [   1,    1,    0, ...,    0,    0,    0]],\n",
       "\n",
       "        [[   1,    1,    1, ...,    0,    0,    0],\n",
       "         [   1,    1,    1, ...,    0,    0,    0],\n",
       "         [   1,    1,    1, ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [   1,    1,    0, ...,    0,    0,    0],\n",
       "         [   1,    1,    0, ...,    0,    0,    0],\n",
       "         [   1,    1,    0, ...,    0,    0,    0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[   1,    1,    1, ...,    0,    0,    0],\n",
       "         [   1,    1,    1, ...,    0,    0,    0],\n",
       "         [   1,    1,    1, ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [   1,    1,    0, ...,    0,    0,    0],\n",
       "         [   1,    1,    0, ...,    0,    0,    0],\n",
       "         [   1,    1,    0, ...,    0,    0,    0]],\n",
       "\n",
       "        [[   1,    1,    1, ...,    0,    0,    0],\n",
       "         [   1,    1,    1, ...,    0,    0,    0],\n",
       "         [   1,    1,    1, ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [   1,    1,    0, ...,    0,    0,    0],\n",
       "         [   1,    1,    0, ...,    0,    0,    0],\n",
       "         [   1,    1,    0, ...,    0,    0,    0]],\n",
       "\n",
       "        [[   1,    1,    1, ...,    0,    0,    0],\n",
       "         [   1,    1,    1, ...,    0,    0,    0],\n",
       "         [   1,    1,    1, ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [   1,    1,    0, ...,    0,    0,    0],\n",
       "         [   1,    1,    0, ...,    0,    0,    0],\n",
       "         [   1,    1,    0, ...,    0,    0,    0]]],\n",
       "\n",
       "\n",
       "       [[[   0,    0,    0, ...,    0,    0,    0],\n",
       "         [   0,    0,    0, ...,    0,    0,    0],\n",
       "         [   0,    0,    0, ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [   0,    0,    0, ...,    0,    0,    0],\n",
       "         [   0,    0,    0, ...,    0,    0,    0],\n",
       "         [   0,    0,    0, ...,    0,    0,    0]],\n",
       "\n",
       "        [[   0,    0,    0, ...,    0,    0,    0],\n",
       "         [   0,    0,    0, ...,    0,    0,    0],\n",
       "         [   0,    0,    0, ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [   0,    0,    0, ...,    0,    0,    0],\n",
       "         [   0,    0,    0, ...,    0,    0,    0],\n",
       "         [   0,    0,    0, ...,    0,    0,    0]],\n",
       "\n",
       "        [[   0,    0,    0, ...,    0,    0,    0],\n",
       "         [   0,    0,    0, ...,    0,    0,    0],\n",
       "         [   0,    0,    0, ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [   0,    0,    0, ...,    0,    0,    0],\n",
       "         [   0,    0,    0, ...,    0,    0,    0],\n",
       "         [   0,    0,    0, ...,    0,    0,    0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[   0,    0,    0, ...,    0,    0,    0],\n",
       "         [   0,    0,    0, ...,    0,    0,    0],\n",
       "         [   0,    0,    0, ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [   0,    0,    0, ...,    0,    0,    0],\n",
       "         [   0,    0,    0, ...,    0,    0,    0],\n",
       "         [   0,    0,    0, ...,    0,    0,    0]],\n",
       "\n",
       "        [[   0,    0,    0, ...,    0,    0,    0],\n",
       "         [   0,    0,    0, ...,    0,    0,    0],\n",
       "         [   0,    0,    0, ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [   0,    0,    0, ...,    0,    0,    0],\n",
       "         [   0,    0,    0, ...,    0,    0,    0],\n",
       "         [   0,    0,    0, ...,    0,    0,    0]],\n",
       "\n",
       "        [[   0,    0,    0, ...,    0,    0,    0],\n",
       "         [   0,    0,    0, ...,    0,    0,    0],\n",
       "         [   0,    0,    0, ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [   0,    0,    0, ...,    0,    0,    0],\n",
       "         [   0,    0,    0, ...,    0,    0,    0],\n",
       "         [   0,    0,    0, ...,    0,    0,    0]]]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 20, 128)\n",
      "tf.Tensor(\n",
      "[    2  1810  7760 10998  5345  5161  1772  5926    34     3  5161  5879\n",
      "  1690  4442  1685  1680  7760 16907  1682  1808  1715  5069  2310    17\n",
      "     3     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0], shape=(128,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "a = next(gen)\n",
    "\n",
    "Y0,Y1,Y2 = a[1][0],a[1][1],a[1][2]\n",
    "\n",
    "print(Y0.shape)\n",
    "\n",
    "Y0 = tf.reshape(Y0, shape=(-1, 128))\n",
    "\n",
    "Y0.shape\n",
    "\n",
    "print(Y0[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(113, 127)\n",
      "(113, 127)\n",
      "(113, 127, 127)\n"
     ]
    }
   ],
   "source": [
    "# tirar as query embeddings\n",
    "mask_q = ((Y1+Y2)==1)[:,1:]\n",
    "mask_sep_tokens = Y0[:,1:][0] == 3\n",
    "mask_q = tf.cast(tf.math.logical_xor(mask_sep_tokens,  (mask_q | mask_sep_tokens)), tf.float32)\n",
    "print()\n",
    "print(mask_q.shape)\n",
    "\n",
    "\n",
    "# tirar as sentences\n",
    "mask_s = tf.cast((Y2==1)[:,1:], tf.float32)\n",
    "print(mask_s.shape)\n",
    "\n",
    "\n",
    "# fazer matrix de interação\n",
    "mask_interaction = tf.einsum(\"bq,bs->bqs\",tf.squeeze(mask_q), tf.squeeze(mask_s))\n",
    "print(mask_interaction.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([113, 127])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden = output.last_hidden_state[:,1:,:] \n",
    "hidden = hidden / tf.norm(hidden, axis=-1, keepdims=True)\n",
    "\n",
    "interaction_matrix = tf.einsum(\"bqe,bse->bqs\", hidden, hidden) * mask_interaction\n",
    "\n",
    "q_matches = tf.cast(tf.reduce_sum(tf.cast(interaction_matrix >= 0.95, tf.int8), axis=-1)>0,tf.float32)\n",
    "q_matches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([113, 127])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#query_matches = tf.cast(tf.reduce_sum(tf.cast(tf.squeeze(x, axis=-1)>=match_threshold, tf.int8), axis=-1)>0,tf.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([113, 127])"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction_matrix = tf.cast(tf.einsum(\"bq,bs->bqs\", input_ids, input_ids)==tf.expand_dims(tf.square(Y0[:,1:]),axis=-1), tf.float32) * mask_interaction  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "qtw_layer = QueryTermWeighting()     \n",
    "\n",
    "#q_emb = output.last_hidden_state[:,1:,:] * tf.expand_dims(mask_q, axis=-1)\n",
    "\n",
    "q_weights = qtw_layer(output.last_hidden_state[:,1:,:], mask=mask_q)\n",
    "\n",
    "tf.reduce_sum(q_weights * q_matches, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(113,), dtype=float32, numpy=\n",
       "array([0.17012967, 0.        , 0.148293  , 0.        , 0.        ,\n",
       "       0.        , 0.03487577, 0.        , 0.07097486, 0.06124848,\n",
       "       0.4395971 , 0.45100248, 0.2145535 , 0.31272617, 0.        ,\n",
       "       0.1266037 , 0.10325293, 0.        , 0.        , 0.06049447,\n",
       "       0.07832406, 0.4352486 , 0.44407433, 0.34385943, 0.3726548 ,\n",
       "       0.38931778, 0.35014176, 0.05771575, 0.04074939, 0.        ,\n",
       "       0.50849384, 0.06118636, 0.        , 0.53054667, 0.36428207,\n",
       "       0.        , 0.14523561, 0.47055268, 0.        , 0.02959868,\n",
       "       0.04281685, 0.12004687, 0.21203166, 0.20622854, 0.06787077,\n",
       "       0.5395304 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.39897323, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.14148958, 0.        , 0.22246706, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.2642048 , 0.        ,\n",
       "       0.        , 0.05228088, 0.        , 0.        , 0.34629756,\n",
       "       0.04055695, 0.11125185, 0.05034116, 0.07355402, 0.05194291,\n",
       "       0.        , 0.45544404, 0.        , 0.        , 0.16900271,\n",
       "       0.        , 0.10649931, 0.        , 0.4826833 , 0.06551673,\n",
       "       0.4047021 , 0.        , 0.38580275, 0.34771344, 0.05182489,\n",
       "       0.06700344, 0.        , 0.        , 0.62302744, 0.        ,\n",
       "       0.04870356, 0.44306254, 0.2052919 , 0.40107006, 0.15439028,\n",
       "       0.        , 0.3867375 , 0.        , 0.396989  , 0.46500254,\n",
       "       0.43087405, 0.38595515, 0.06450707], dtype=float32)>"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(113, 127, 768), dtype=float32, numpy=\n",
       "array([[[-9.97197628e-01,  8.22079003e-01,  1.37871742e-01, ...,\n",
       "          1.05122340e+00,  9.97862041e-01, -1.11376762e+00],\n",
       "        [ 7.29606569e-01,  2.77180552e-01,  5.56441307e-01, ...,\n",
       "         -2.01994970e-01,  5.64241052e-01, -1.34539217e-01],\n",
       "        [ 3.21850270e-01,  9.25644338e-02,  5.59158385e-01, ...,\n",
       "          9.66627598e-01,  5.34669459e-01, -3.57550293e-01],\n",
       "        ...,\n",
       "        [-5.95068857e-02,  6.22919977e-01,  2.34810039e-01, ...,\n",
       "          2.04758286e-01,  4.04620826e-01, -5.64388514e-01],\n",
       "        [-5.01044393e-01,  2.29121402e-01, -5.80734491e-01, ...,\n",
       "         -5.04128993e-01,  2.92268664e-01,  4.56588507e-01],\n",
       "        [-5.52678108e-01,  2.48574167e-01, -4.88777459e-01, ...,\n",
       "         -5.96769452e-01,  3.83230954e-01,  4.54718083e-01]],\n",
       "\n",
       "       [[-1.22354209e+00,  8.41383994e-01, -6.24941811e-02, ...,\n",
       "          1.12025619e+00,  9.84804511e-01, -1.08045471e+00],\n",
       "        [ 3.67276490e-01,  5.53612113e-01,  3.03955644e-01, ...,\n",
       "          1.02980793e-01,  4.51413751e-01, -3.52868021e-01],\n",
       "        [ 3.28982845e-02,  2.53663301e-01,  2.04866886e-01, ...,\n",
       "          1.18095255e+00,  2.74862707e-01, -1.79500014e-01],\n",
       "        ...,\n",
       "        [ 1.74209028e-02,  4.66754764e-01,  5.92561774e-02, ...,\n",
       "         -1.24149874e-01,  3.82794321e-01, -3.27693522e-01],\n",
       "        [-5.55056870e-01,  1.85259372e-01, -4.87639189e-01, ...,\n",
       "         -4.81869340e-01,  3.69248271e-01,  5.05440593e-01],\n",
       "        [-5.51524997e-01,  2.32404545e-01, -3.43127996e-01, ...,\n",
       "         -4.92394835e-01,  2.43402883e-01,  6.04583621e-01]],\n",
       "\n",
       "       [[-1.14451444e+00,  9.14709151e-01,  8.21680501e-02, ...,\n",
       "          9.92421091e-01,  9.29976344e-01, -1.16450107e+00],\n",
       "        [ 7.64302611e-01,  4.58824694e-01,  6.25388920e-01, ...,\n",
       "         -3.18180770e-01,  7.16857314e-01, -1.54685855e-01],\n",
       "        [ 2.58432567e-01,  2.49719068e-01,  6.87560499e-01, ...,\n",
       "          8.73543978e-01,  6.20532155e-01, -2.11041242e-01],\n",
       "        ...,\n",
       "        [ 3.74828875e-02,  4.50530112e-01,  2.95570374e-01, ...,\n",
       "         -9.16831866e-02,  4.34738100e-01, -5.31701982e-01],\n",
       "        [-4.88473952e-01,  2.84665704e-01,  1.93467215e-02, ...,\n",
       "         -4.24880028e-01,  4.97163296e-01, -1.40556008e-01],\n",
       "        [-5.47170043e-01,  5.93093522e-02, -2.62953341e-01, ...,\n",
       "         -5.40206015e-01,  2.31229514e-01,  5.44243753e-01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.42257583e+00,  6.97534144e-01,  7.22474754e-02, ...,\n",
       "          1.07873297e+00,  9.20648456e-01, -8.32912028e-01],\n",
       "        [ 9.10600245e-01,  2.44745657e-01,  5.48074126e-01, ...,\n",
       "         -3.31476033e-01,  5.46525478e-01, -2.68093169e-01],\n",
       "        [ 2.53239632e-01,  1.77526847e-01,  6.39519930e-01, ...,\n",
       "          7.75891781e-01,  7.20346391e-01, -5.49176574e-01],\n",
       "        ...,\n",
       "        [ 1.17521420e-01, -3.93379480e-04,  2.90500790e-01, ...,\n",
       "          7.79440030e-02,  2.66304225e-01,  3.00877243e-02],\n",
       "        [-3.05548131e-01, -3.28957289e-03, -4.09448206e-01, ...,\n",
       "         -4.23025846e-01,  4.36399937e-01,  6.19173646e-01],\n",
       "        [-3.90432775e-01, -1.03685558e-02, -3.73236164e-02, ...,\n",
       "         -3.76522541e-01,  4.60959017e-01,  6.90772772e-01]],\n",
       "\n",
       "       [[-1.23249221e+00,  7.22694218e-01,  1.82903051e-01, ...,\n",
       "          1.08554053e+00,  1.18827367e+00, -9.03986156e-01],\n",
       "        [ 8.43333125e-01,  3.02043200e-01,  4.50956523e-01, ...,\n",
       "         -3.09529305e-01,  7.50427783e-01, -3.71702254e-01],\n",
       "        [ 4.43344533e-01,  2.30235785e-01,  5.22319973e-01, ...,\n",
       "          7.30421901e-01,  8.53051186e-01, -5.36594450e-01],\n",
       "        ...,\n",
       "        [ 1.43611073e-01,  2.38987684e-01,  3.35826904e-01, ...,\n",
       "         -3.13922353e-02,  3.41798663e-01, -1.47032753e-01],\n",
       "        [-4.21154767e-01,  1.87039718e-01, -2.67982721e-01, ...,\n",
       "         -6.48605883e-01,  4.37165260e-01,  6.85993850e-01],\n",
       "        [-6.88959301e-01,  2.19181776e-01,  3.07661325e-01, ...,\n",
       "         -6.89903557e-01,  4.98952568e-01,  5.67819893e-01]],\n",
       "\n",
       "       [[-1.15849710e+00,  8.12860072e-01,  7.56681412e-02, ...,\n",
       "          1.03511536e+00,  9.68608141e-01, -1.02377975e+00],\n",
       "        [ 1.17698014e-01,  5.19204736e-01,  4.00209546e-01, ...,\n",
       "         -3.34880382e-01,  4.48349714e-01, -3.71681333e-01],\n",
       "        [-1.80087611e-02,  2.45877743e-01,  5.80135763e-01, ...,\n",
       "          6.04273200e-01,  8.28697622e-01, -4.59129035e-01],\n",
       "        ...,\n",
       "        [ 9.37900618e-02,  3.43148291e-01,  3.43867958e-01, ...,\n",
       "         -1.58600539e-01,  2.63633579e-01, -2.67109275e-01],\n",
       "        [-3.53597403e-01,  1.65816426e-01, -4.36674476e-01, ...,\n",
       "         -3.94211233e-01,  3.47095728e-01,  6.72325134e-01],\n",
       "        [-6.16838694e-01,  1.97384268e-01,  3.62695456e-02, ...,\n",
       "         -4.44887489e-01,  1.97537988e-01,  6.99948788e-01]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.last_hidden_state[:,1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 2, 2])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(12,), dtype=int64, numpy=array([5, 5, 5, 0, 4, 4, 0, 0, 3, 0, 0, 0])>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=int64, numpy=array([5, 5, 5, 4, 4, 3])>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-3f7344ada3c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mscatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmnrm.dataset import TestCollectionV2, TrainCollectionV2\n",
    "\n",
    "train_collection = TrainCollectionV2\\\n",
    "                                .load(\"training_batch_01_250\")\\\n",
    "                                .batch_size(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "q, pos_doc, neg_doc = next(train_collection.generator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['How many genes in S. cerevisiae are the result of an ancient whole genome duplication?',\n",
       "       'What is FINDbase?',\n",
       "       'Are stress granules involved in the pathogenesis of Amyotrophic Lateral Sclerosis?',\n",
       "       'Is the crystal structure of Pim-1 available?',\n",
       "       'What is the mechanism of action of  trichostatin A (TSA) as an antitumoral agent?',\n",
       "       'Which diseases are associated with Alu element insertion?',\n",
       "       'List disorders that are caused by mutations in the mitochondrial MTND6 gene.',\n",
       "       'What does isradipine do to L-type channels?',\n",
       "       'Where, in the body, would the Cobb-Stainsby excision arthroplasty be performed?',\n",
       "       'Which are the main causes of fetal echogenic bowel?',\n",
       "       'For which indications has midostaurin received FDA and EMA approval?',\n",
       "       'Is subdural empyema a complication of sinusitis?',\n",
       "       'Which drug can be reversed with idarucizumab?',\n",
       "       'List human diseases involving genomic imprinting.',\n",
       "       'Which tool exists for microsatellite (SSR) loci detection and primer design?',\n",
       "       'Is RASA2 involved in melanoma?', 'What is Genomicus?',\n",
       "       'Which is the most known bacterium responsible for botulism (sausage-poisoning)?',\n",
       "       'What is known about thalidomide therapy and survival of glioblastoma patients?',\n",
       "       'Which G protein is essential in the formation and function of lamellipodia?',\n",
       "       'Has Revlimid been approved by the US Food and Drug Administration?',\n",
       "       'Is intraoperative radiotherapy used for treatment of glioblastoma?',\n",
       "       'Are sleep apnea and snoring associated with cardiac arrhythmias?',\n",
       "       'Do archaeal genomes contain one or multiple origins of replication?',\n",
       "       'Is overproduction of transthyretin is associated with amyloidosis associated neuropathy?',\n",
       "       'Do carmustine wafers improve survival of glioblastoma patients?',\n",
       "       'Which Python tool has been developed for network-based stratification of tumor mutations?',\n",
       "       'Describe genomiser', 'What is COG112?',\n",
       "       'How does Dst1 knock-out affect transcription in yeast?',\n",
       "       'What is MINDY-1?',\n",
       "       'Has protein citrullination been implicated in rheumatoid arthritis?'],\n",
       "      dtype='<U89')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_collection = TestCollectionV2.load(\"validation_data_batch_01_250\")\\\n",
    "                                    .batch_size(32)\\\n",
    "                                    .set_transform_inputs_fn(test_gen)\\\n",
    "                                    .set_name(\"Validation TOP 250\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_q_results():\n",
    "    q_results = defaultdict(list)\n",
    "    count = 0\n",
    "    for q_id, Y, docs_id in validation_collection.generator():\n",
    "\n",
    "        count+=1\n",
    "        if count%8 == 0:\n",
    "            print(count)\n",
    "        for i in range(len(q_id)):\n",
    "            q_results[q_id[i]].append(docs_id[i][\"id\"])\n",
    "    return q_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "16\n",
      "24\n",
      "32\n",
      "40\n",
      "48\n",
      "56\n",
      "64\n",
      "72\n",
      "80\n",
      "88\n",
      "96\n",
      "8\n",
      "16\n",
      "24\n",
      "32\n",
      "40\n",
      "48\n",
      "56\n",
      "64\n",
      "72\n",
      "80\n",
      "88\n",
      "96\n",
      "104\n",
      "112\n",
      "120\n",
      "128\n",
      "136\n",
      "144\n",
      "152\n",
      "160\n",
      "168\n",
      "176\n",
      "184\n",
      "192\n",
      "200\n",
      "208\n",
      "216\n",
      "224\n",
      "232\n",
      "240\n",
      "248\n",
      "256\n",
      "264\n",
      "272\n",
      "280\n",
      "288\n",
      "296\n",
      "304\n",
      "312\n",
      "320\n",
      "328\n",
      "336\n",
      "344\n",
      "352\n",
      "360\n",
      "368\n",
      "376\n",
      "384\n",
      "392\n",
      "400\n",
      "408\n",
      "416\n",
      "424\n",
      "432\n",
      "440\n",
      "448\n",
      "456\n",
      "464\n",
      "472\n",
      "480\n",
      "488\n",
      "496\n",
      "504\n",
      "512\n",
      "520\n",
      "528\n",
      "536\n",
      "544\n",
      "552\n",
      "560\n",
      "568\n",
      "576\n",
      "584\n",
      "592\n",
      "600\n",
      "608\n",
      "616\n",
      "624\n",
      "632\n",
      "640\n",
      "648\n",
      "656\n",
      "664\n",
      "672\n",
      "680\n",
      "688\n",
      "696\n",
      "704\n",
      "712\n",
      "720\n",
      "728\n",
      "736\n",
      "744\n",
      "752\n",
      "760\n",
      "768\n",
      "776\n"
     ]
    }
   ],
   "source": [
    "validation_collection.batch_size(250)\n",
    "original = get_q_results()\n",
    "\n",
    "validation_collection.batch_size(32)\n",
    "withbatch32 = get_q_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation_collection.batch_size(32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "different_samples = 0\n",
    "for k in original.keys():\n",
    "\n",
    "    for i in range(min(len(withbatch32[k]), len(original[k]))):\n",
    "        if original[k][i] != withbatch32[k][i]:\n",
    "            different_samples += 1\n",
    "        \n",
    "    different_samples += max(len(withbatch32[k]), len(original[k])) - min(len(withbatch32[k]), len(original[k]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "different_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert_model = TFBertModel.from_pretrained('microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract', \n",
    "                                             output_attentions = False,\n",
    "                                             output_hidden_states = False,\n",
    "                                             return_dict=True,\n",
    "                                             from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  109482240 \n",
      "=================================================================\n",
      "Total params: 109,482,240\n",
      "Trainable params: 109,482,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_17:0\", shape=(None, 20, 128), dtype=int32)\n",
      "Tensor(\"input_18:0\", shape=(None, 20, 128), dtype=int32)\n",
      "Tensor(\"input_19:0\", shape=(None, 20, 128), dtype=int32)\n",
      "Tensor(\"input_20:0\", shape=(None, 20), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for _input in rank_model.inputs:\n",
    "    _input.shape[0]\n",
    "    print(tf.keras.layers.Input(_input.shape[1:], dtype=\"int32\"))#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-bioasq",
   "language": "python",
   "name": "py-bioasq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
