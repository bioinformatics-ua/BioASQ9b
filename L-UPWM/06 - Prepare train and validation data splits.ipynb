{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import sys\n",
    "import subprocess\n",
    "import shutil\n",
    "from os.path import join\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from nir.utils import create_filter_query_function, change_bm25_parameters\n",
    "from utils import *\n",
    "import pickle\n",
    "from mmnrm.dataset import TrainCollectionV2, TestCollectionV2\n",
    "from mmnrm.evaluation import BioASQ_Evaluator\n",
    "\n",
    "import json\n",
    "\n",
    "es = Elasticsearch([\"http://193.136.175.98:8125\"])\n",
    "\n",
    "index_name = \"bioasq_9b\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "3643\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "queries = load_queries(\"training9b_wDates.json\", maps=[(\"body\",\"query\")])\n",
    "\n",
    "test_8b = []\n",
    "\n",
    "for i in range(1,6):\n",
    "    id_sets = set()\n",
    "    with open(f\"yearly_data/8B{i}_golden.json\",\"r\") as f:\n",
    "        for q in json.load(f)[\"questions\"]:\n",
    "            id_sets.add(q[\"id\"])\n",
    "            \n",
    "    test_8b.append(id_sets)\n",
    "\n",
    "print(sum([len(x) for x in test_8b]))\n",
    "\n",
    "queries_ids_sets = { x[\"id\"] for x in queries }\n",
    "train_ids = queries_ids_sets - test_8b[0]\n",
    "validations_ids = test_8b[0]\n",
    "\n",
    "train_data = subset_byId(queries, train_ids)\n",
    "validation_data = subset_byId(queries, validations_ids)\n",
    "\n",
    "convert_to_trainable_gs = lambda x: { k:{1:v}for k,v in x.items()}\n",
    "\n",
    "train_data_queries, train_data_gs = separate_queries_goldstandard(train_data, additional_keys=[\"limit_date\"])\n",
    "train_data_gs = convert_to_trainable_gs(train_data_gs)\n",
    "print(len(train_data))\n",
    "validation_data_queries, validation_data_gs = separate_queries_goldstandard(validation_data, additional_keys=[\"limit_date\"])\n",
    "print(len(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting the k1 and b for BM25\n",
      "Minimum number of relevance type(0) in the queries of the goldstandard sub set: 43\n",
      "Mean number of relevance type(0) in the queries of the goldstandard sub set: 93.25704225352112\n",
      "Minimum number of relevance type(1) in the queries of the goldstandard sub set: 1\n",
      "Mean number of relevance type(1) in the queries of the goldstandard sub set: 6.742957746478873\n",
      "Sub Collection size 278351\n",
      "Number of skipped question, due to lack of true positives 235\n",
      "Setting the k1 and b for BM25\n",
      "Setting the k1 and b for BM25\n",
      "Minimum number of relevance type(0) in the queries of the goldstandard sub set: 163\n",
      "Mean number of relevance type(0) in the queries of the goldstandard sub set: 242.2012910798122\n",
      "Minimum number of relevance type(1) in the queries of the goldstandard sub set: 1\n",
      "Mean number of relevance type(1) in the queries of the goldstandard sub set: 7.798708920187793\n",
      "Sub Collection size 649700\n",
      "Number of skipped question, due to lack of true positives 0\n",
      "Setting the k1 and b for BM25\n",
      "Running query: 80\r"
     ]
    }
   ],
   "source": [
    "# make a BM25 search\n",
    "\n",
    "experiments = [(0.9, 0.4, 100), (0.6, 0.4, 250)]\n",
    "\n",
    "for K1,BETA,TOP_N in experiments:\n",
    "\n",
    "    query_results = execute_search(es, train_data_queries, TOP_N, index_name, k1=K1, b=BETA)\n",
    "\n",
    "    t_collection = TrainCollectionV2(train_data_queries, \n",
    "                                   train_data_gs, \n",
    "                                   query_results, \n",
    "                                   use_relevance_groups=False)\\\n",
    "                            .batch_size(32)\n",
    "\n",
    "    t_collection.save(\"training_batch_01_\"+str(TOP_N))\n",
    "\n",
    "    ## VALIDATION DATA\n",
    "\n",
    "    query_results = execute_search(es, validation_data_queries, TOP_N, index_name, k1=K1, b=BETA)\n",
    "\n",
    "    validation_data_gs = list(map(lambda x:{\"id\":x[\"id\"], \n",
    "                                            \"query\":x[\"query\"], \n",
    "                                            \"documents\":[y.split(\"/\")[-1] for y in x[\"documents\"]],\n",
    "                                            \"limit_date\":x[\"limit_date\"]},\n",
    "                                           validation_data))\n",
    "\n",
    "    evaluator = BioASQ_Evaluator(validation_data_gs)\n",
    "\n",
    "    validation_collection = TestCollectionV2(validation_data_queries, \n",
    "                                               query_results,\n",
    "                                               evaluator)\\\n",
    "                                        .batch_size(32)\n",
    "\n",
    "    validation_collection.save(\"validation_data_batch_01_\"+str(TOP_N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-bioasq",
   "language": "python",
   "name": "py-bioasq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
